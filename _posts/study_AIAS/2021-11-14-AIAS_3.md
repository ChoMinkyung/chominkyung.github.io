---
toc: true
toc_label: "Table of Contents"
toc_icon: "cog"
toc_sticky: true

layout:
title: "[인공지능 응용 시스템] Lecture2 - 3. Nearest Neighbors"
excerpt:
date: 2021-11-14
last_modified_at: 2021-10-10
categories:
  - Aias
tags:
  - [인공지능, 머신러닝, 딥러닝]

use_math: true
comments: true
share: false
---

---

<div style="text-align: right"> Lecture 2</div>

## 3. Nearest Neighbors

<br>

### \* Image Classification

(1) Semantic Gap : 기존 영상 분류의 문제점, 사람이 영상을 인식하는 방식과 디지털 RGB 방식의 차이에서 비롯된 것<br>
<br>
(2) Challenges<br>
① Viewpoint variation : View point(촬영하는 카메라의 위치)가 변할 때 물체 인식<br>
② Background Clutter : 배경과 물체의 구분하여 인식<br>
③ Illumination : 밝기에 따른 물체 인식<br>
④ Occlusion : 인식대상인 물체가 가려지거나 다른 물체와 겹쳐졌을 때 물체 인식<br>
⑤ Intra-class variation vs. Inter-class variation : 종내 다양성, 같은 종이라도 다른 물체로 인식<br>
(Intra-class : 같은 클래스 내의 feature의 거리, Inter-class 각 클래스끼리의 거리)<br>
<br>

### \* Machine Learning : Data-Driven Approach

1. 모든 data를 label(정답)과 함께 수집<br>
2. 데이터셋을 머신러닝으로 학습<br>
3. 새로운 query data와 Distance Metrix로 계산해 값 R로 매핑하여 새로운 data 분류<br>
   -> 모든 data와 거리 계산 후 가까운 순으로 정렬<br>
   <br>

### \* Distance Metrix

(1) L1 distance<br>

![L1distance ](https://user-images.githubusercontent.com/58170545/141673334-9934f205-ab7e-45e3-87b2-344640eaf533.png){: .align-center width="50%" height="50%"}
<br>
(2) L2 distance<br>

![L2distance](https://user-images.githubusercontent.com/58170545/141673346-87d49786-89c6-42c3-980a-424341aa5d3d.png){: .align-center width="50%" height="50%"}
<br>

### \* Nearest Neighbor

: 최근접 이웃 탐색(nearest neighbor search)은 가장 가까운 (또는 가장 근접한) 점을 찾기 위한 최적화 문제이며 모든 data와 label을 Memorize하는 train 부분과 학습된 data 중에서 가장 가까운 label을 예측하는 Predict 부분으로 나뉩니다.<br>
<br>
그러나 수행 시간이 O(N)으로 너무 오래 걸린다는 한계점이 있습니다. 그래서 Hyperparameters를 사용합니다.<br>
<br>
(1) Hyperparameters <br>

- K : 데이터를 분류하기 위해 비교할 때 사용하는 데이터의 수<br>
- distance : 데이터를 분류하기 위한 데이터 간 거리를 구하는 방식<br>
  <br>
  k가 작을수록 불안정한 결과가 나와 오버피팅이 일어나고 k가 클수록 지나친 일반화로 언더피팅이 일어나는 데이터 의존적인 변수이기에 가장 적합한 hyperparameter를 찾는 것이 중요합니다.
  <br>
